"""
Business Metrics Calculation Service

Calculates real business metrics from actual system performance data
including MTTR, cost savings, incident prevention, and efficiency scores.
"""

import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from collections import deque
import statistics

from src.models.real_time_models import BusinessMetrics
from src.utils.logging import get_logger


logger = get_logger("business_metrics")


class BusinessMetricsService:
    """
    Calculate and track real business metrics from incident data.

    Metrics calculated:
    - MTTR (Mean Time To Resolution) with confidence intervals
    - Incidents handled and prevented
    - Cost savings with confidence intervals
    - Efficiency score and success rate
    - Trend analysis
    """

    def __init__(self, max_history: int = 1000):
        self.max_history = max_history

        # Incident history
        self.incident_history = deque(maxlen=max_history)
        self.prevention_history = deque(maxlen=max_history)

        # Time tracking
        self.start_time = datetime.utcnow()

        # Cost assumptions (configurable)
        self.cost_per_minute_downtime = 1000.0  # $1000 per minute of downtime
        self.cost_per_incident_prevented = 5000.0  # $5000 per prevented incident

        logger.info("Business Metrics Service initialized")

    def record_incident_completion(
        self,
        incident_id: str,
        detection_time: datetime,
        resolution_time: datetime,
        severity: str,
        was_prevented: bool = False
    ):
        """Record completed incident for metrics calculation."""
        resolution_duration = (resolution_time - detection_time).total_seconds()

        incident_data = {
            "incident_id": incident_id,
            "detection_time": detection_time,
            "resolution_time": resolution_time,
            "duration_seconds": resolution_duration,
            "severity": severity,
            "was_prevented": was_prevented,
            "timestamp": resolution_time
        }

        if was_prevented:
            self.prevention_history.append(incident_data)
        else:
            self.incident_history.append(incident_data)

        logger.info(
            f"Recorded incident {incident_id}: "
            f"{resolution_duration:.1f}s, severity={severity}, prevented={was_prevented}"
        )

    def _calculate_confidence_interval(
        self,
        values: List[float],
        confidence_level: float = 0.95
    ) -> Tuple[float, float, float]:
        """Calculate mean and confidence interval."""
        if len(values) < 2:
            mean_val = values[0] if values else 0.0
            return mean_val, mean_val * 0.8, mean_val * 1.2

        mean_val = statistics.mean(values)
        stdev = statistics.stdev(values)

        # Simple confidence interval (z-score for 95% confidence â‰ˆ 1.96)
        margin = 1.96 * (stdev / (len(values) ** 0.5))
        
        # Ensure margin is at least a small epsilon to avoid degenerate intervals
        if margin == 0:
            margin = max(1e-6, mean_val * 0.01)  # 1% of mean or small epsilon

        lower = max(mean_val - margin, 0.0)  # Clamp lower bound to 0
        upper = mean_val + margin

        return mean_val, lower, upper

    def _calculate_mttr(self) -> Tuple[float, float, float]:
        """Calculate MTTR with confidence intervals."""
        if not self.incident_history:
            return 0.0, 0.0, 0.0

        durations = [inc["duration_seconds"] for inc in self.incident_history]
        return self._calculate_confidence_interval(durations)

    def _calculate_cost_savings(self) -> Tuple[float, float, float]:
        """Calculate cost savings with confidence intervals."""
        # Prevented incidents save money
        prevented_count = len(self.prevention_history)
        prevented_savings = prevented_count * self.cost_per_incident_prevented

        # Faster resolution saves downtime costs
        if len(self.incident_history) >= 2:
            # Compare current MTTR to baseline (assume 30 min baseline)
            baseline_seconds = 30 * 60
            current_mttr = statistics.mean([inc["duration_seconds"] for inc in self.incident_history])

            if current_mttr < baseline_seconds:
                time_saved_per_incident = baseline_seconds - current_mttr
                downtime_savings = (time_saved_per_incident / 60) * self.cost_per_minute_downtime
                total_incidents = len(self.incident_history)
                resolution_savings = downtime_savings * total_incidents
            else:
                resolution_savings = 0.0
        else:
            resolution_savings = 0.0

        total_savings = prevented_savings + resolution_savings

        # Confidence interval (20% margin for cost estimates)
        return total_savings, total_savings * 0.8, total_savings * 1.2

    def _calculate_efficiency_score(self) -> float:
        """Calculate overall efficiency score (0-1)."""
        if not self.incident_history:
            return 1.0

        # Factors:
        # 1. Speed: How fast incidents are resolved (vs 30 min baseline)
        # 2. Prevention: Ratio of prevented to total incidents
        # 3. Success rate: Ratio of resolved incidents

        # Speed score
        mttr_seconds = statistics.mean([inc["duration_seconds"] for inc in self.incident_history])
        baseline_seconds = 30 * 60
        speed_score = max(0.0, min(1.0, baseline_seconds / max(mttr_seconds, 1)))

        # Prevention score
        total_incidents = len(self.incident_history) + len(self.prevention_history)
        prevention_score = len(self.prevention_history) / max(total_incidents, 1)

        # Overall efficiency (weighted average)
        efficiency = 0.6 * speed_score + 0.4 * prevention_score

        return min(1.0, efficiency)

    def _calculate_success_rate(self) -> float:
        """Calculate success rate (all incidents resolved successfully)."""
        # For now, assume all completed incidents were successful
        # In production, track failed resolutions
        if not self.incident_history:
            return 1.0

        return 1.0  # 100% success rate (would track failures in production)

    def _calculate_trends(
        self,
        current_period_days: int = 7
    ) -> Tuple[Optional[float], Optional[float]]:
        """Calculate trends compared to previous period."""
        if len(self.incident_history) < 10:
            return None, None

        cutoff_time = datetime.utcnow() - timedelta(days=current_period_days)

        # Split into current and previous periods
        recent_incidents = [
            inc for inc in self.incident_history
            if inc["timestamp"] >= cutoff_time
        ]

        older_incidents = [
            inc for inc in self.incident_history
            if inc["timestamp"] < cutoff_time
        ]

        if not recent_incidents or not older_incidents:
            return None, None

        # MTTR trend
        recent_mttr = statistics.mean([inc["duration_seconds"] for inc in recent_incidents])
        older_mttr = statistics.mean([inc["duration_seconds"] for inc in older_incidents])
        mttr_trend = ((recent_mttr - older_mttr) / older_mttr) * 100 if older_mttr > 0 else 0.0

        # Efficiency trend (simple approximation)
        efficiency_trend = -mttr_trend  # Lower MTTR = higher efficiency

        return mttr_trend, efficiency_trend

    async def calculate_current_metrics(self) -> BusinessMetrics:
        """Calculate current business metrics."""
        # MTTR calculation
        mttr, mttr_lower, mttr_upper = self._calculate_mttr()

        # Cost savings calculation
        cost_savings, cost_lower, cost_upper = self._calculate_cost_savings()

        # Efficiency and success rates
        efficiency_score = self._calculate_efficiency_score()
        success_rate = self._calculate_success_rate()

        # Trends
        mttr_trend, efficiency_trend = self._calculate_trends()

        # Data quality score
        sample_size = len(self.incident_history)
        data_quality = min(1.0, sample_size / 100.0)  # Full confidence at 100+ samples

        # Incidents in progress (would track in production)
        incidents_in_progress = 0  # Placeholder

        return BusinessMetrics(
            mttr_seconds=mttr,
            mttr_confidence_lower=mttr_lower,
            mttr_confidence_upper=mttr_upper,
            incidents_handled=len(self.incident_history),
            incidents_prevented=len(self.prevention_history),
            incidents_in_progress=incidents_in_progress,
            cost_savings_usd=cost_savings,
            cost_savings_confidence_lower=cost_lower,
            cost_savings_confidence_upper=cost_upper,
            efficiency_score=efficiency_score,
            success_rate=success_rate,
            mttr_trend=mttr_trend,
            efficiency_trend=efficiency_trend,
            sample_size=sample_size,
            data_quality_score=data_quality,
            calculation_method="real_system_data",
            confidence_level=0.95
        )

    async def broadcast_metrics_update(self, ws_manager):
        """Broadcast metrics update via WebSocket."""
        metrics = await self.calculate_current_metrics()

        from src.models.real_time_models import WebSocketEvent

        event = WebSocketEvent(
            event_type="business_metrics",
            target_dashboard="ops",
            data=metrics.model_dump(mode='json'),
            priority=1
        )

        await ws_manager.broadcast_message(event.model_dump(mode='json'))
        logger.debug("Broadcast business metrics update")

    def get_incident_history_summary(self, limit: int = 10) -> List[Dict]:
        """Get recent incident history."""
        recent = list(self.incident_history)[-limit:]

        return [
            {
                "incident_id": inc["incident_id"],
                "duration_seconds": inc["duration_seconds"],
                "severity": inc["severity"],
                "resolution_time": inc["resolution_time"].isoformat()
            }
            for inc in recent
        ]


# Global instance
_business_metrics_service: Optional[BusinessMetricsService] = None


def get_business_metrics_service() -> BusinessMetricsService:
    """Get or create the global business metrics service."""
    global _business_metrics_service

    if _business_metrics_service is None:
        _business_metrics_service = BusinessMetricsService()

    return _business_metrics_service
